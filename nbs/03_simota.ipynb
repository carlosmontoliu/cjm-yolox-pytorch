{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simota\n",
    "\n",
    "> An implementation of SimOTA label assignment for the [YOLOX](https://arxiv.org/abs/2107.08430) object detection model based on [OpenMMLab](https://github.com/open-mmlab)â€™s implementation in the [mmdetection](https://github.com/open-mmlab/mmdetection) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp simota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Type, List, Optional, Callable, Tuple, Union\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class AssignResult:\n",
    "    \"\"\"\n",
    "    Stores assignments between predicted bounding boxes and actual truth bounding boxes.\n",
    "    \n",
    "    Based on OpenMMLab's implementation in the mmdetection library:\n",
    "    \n",
    "    - [OpenMMLab's Implementation](https://github.com/open-mmlab/mmdetection/blob/d64e719172335fa3d7a757a2a3636bd19e9efb62/mmdet/core/bbox/assigners/assign_result.py#L7)\n",
    "\n",
    "    \"\"\"\n",
    "    num_ground_truth_boxes: int # The number of actual truth boxes considered when computing this assignment\n",
    "    ground_truth_box_indices: torch.LongTensor # For each predicted bounding box, this indicates the 1-based index of the assigned actual truth box. 0 means unassigned and -1 means ignore.\n",
    "    max_iou_values: torch.FloatTensor # The Intersection over Union (IoU) between the predicted bounding box and its assigned actual truth box.\n",
    "    category_labels: torch.LongTensor = field(default=None) # If specified, for each predicted bounding box, this indicates the category label of the assigned actual truth box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SimOTAAssigner():\n",
    "    \"\"\"\n",
    "    Computes matching between predictions and ground truth.\n",
    "    \n",
    "    Based on OpenMMLab's implementation in the mmdetection library:\n",
    "    \n",
    "    - [OpenMMLab's Implementation](https://github.com/open-mmlab/mmdetection/blob/d64e719172335fa3d7a757a2a3636bd19e9efb62/mmdet/core/bbox/assigners/sim_ota_assigner.py#L14)\n",
    "    \n",
    "    \n",
    "    #### Pseudocode\n",
    "\n",
    "    1. Receive as input: predicted_scores, priors, decoded_bounding_boxes, ground_truth_bounding_boxes, and ground_truth_labels. These are all tensors.\n",
    "    2. Initialize a large value for HIGH_COST_VALUE.\n",
    "    3. Calculate the number of ground truth bounding boxes and predicted bounding boxes.\n",
    "    4. Create a tensor `assigned_gt_inds` with the same size as the number of predicted bounding boxes and fill it with zeros. \n",
    "    5. If there are no ground truth bounding boxes or predicted bounding boxes, return an `AssignResult` with no assignments.\n",
    "    6. If there are no ground truth bounding boxes, assign all predicted bounding boxes to the background.\n",
    "    7. Calculate which priors are within a ground truth bounding box and which priors are in the center of a ground truth bounding box.\n",
    "    8. Extract the valid decoded bounding boxes and valid predicted scores, i.e., those that are inside a ground truth bounding box and at the center.\n",
    "    9. Compute the IoU between valid bounding boxes and ground truth bounding boxes. \n",
    "        - Calculate the IoU cost by taking the negative logarithm of this IoU.\n",
    "    10. Convert the ground truth labels to one-hot format and calculate the classification cost using the valid predicted scores and one-hot ground truth labels.\n",
    "    11. Calculate the total cost matrix by adding up the classification cost, the IoU cost and, if not within a ground truth bounding box and at the center, a high cost.\n",
    "    12. Use the dynamic_k_matching method on the cost matrix to perform a dynamic matching between the ground truth bounding boxes and valid bounding boxes.\n",
    "        - Obtain the matched ground truth indices and IoU scores.\n",
    "    13. Update the `assigned_gt_inds` with the matched ground truth indices.\n",
    "    14. Create a tensor `assigned_labels` of the same size as `assigned_gt_inds`, and fill it with -1.\n",
    "        - Update `assigned_labels` with the labels of the matched ground truth boxes.\n",
    "    15. Create a tensor `max_overlaps` of the same size as `assigned_gt_inds`, and fill it with -HIGH_COST_VALUE.\n",
    "        - Update `max_overlaps` with the IoU scores of the matched ground truth boxes.\n",
    "    16. Return an instance of `AssignResult` with the number of ground truth boxes, the `assigned_gt_inds`, `max_overlaps`, and `assigned_labels`.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 center_radius:float=2.5, # Ground truth center size to judge whether a prior is in center.\n",
    "                 candidate_topk:int=10, # The candidate top-k which used to get top-k ious to calculate dynamic-k.\n",
    "                 iou_weight:float=3.0, # The scale factor for regression iou cost.\n",
    "                 cls_weight:float=1.0 # The scale factor for classification cost.\n",
    "                ):\n",
    "        self.center_radius = center_radius\n",
    "        self.candidate_topk = candidate_topk\n",
    "        self.iou_weight = iou_weight\n",
    "        self.cls_weight = cls_weight\n",
    "\n",
    "    def assign(self,\n",
    "           pred_scores,\n",
    "           priors,\n",
    "           decoded_bboxes,\n",
    "           gt_bboxes,\n",
    "           gt_labels,\n",
    "           gt_bboxes_ignore=None,\n",
    "           eps=1e-7):\n",
    "        \"\"\"Assign ground truth to priors using SimOTA (Similarity-Overlap-Training-Assignment).\n",
    "\n",
    "        This method finds the best assignment of predicted bounding boxes (priors) to \n",
    "        the ground truth bounding boxes (gt) based on a combination of classification and \n",
    "        regression (IoU) costs.\n",
    "\n",
    "        Args:\n",
    "            pred_scores (Tensor): Classification scores of each prior box across all classes. \n",
    "                It is a 2D-Tensor with shape [num_priors, num_classes].\n",
    "            priors (Tensor): Prior bounding boxes of one image in format [cx, xy, stride_w, stride_y].\n",
    "                It is a 2D-Tensor with shape [num_priors, 4].\n",
    "            decoded_bboxes (Tensor): Predicted bounding boxes of one image in format [tl_x, tl_y, br_x, br_y].\n",
    "                It is a 2D-Tensor with shape [num_priors, 4].\n",
    "            gt_bboxes (Tensor): Ground truth bounding boxes of one image in format [tl_x, tl_y, br_x, br_y].\n",
    "                It is a 2D-Tensor with shape [num_gts, 4].\n",
    "            gt_labels (Tensor): Ground truth labels of one image, \n",
    "                It is a Tensor with shape [num_gts].\n",
    "            gt_bboxes_ignore (Tensor, optional): Ground truth bounding boxes that are\n",
    "                labelled as `ignored`, e.g., crowd boxes in COCO.\n",
    "            eps (float): A value added to the denominator for numerical\n",
    "                stability. Default 1e-7.\n",
    "\n",
    "        Returns:\n",
    "            :obj:`AssignResult`: The assigned result. This includes information about the index \n",
    "                of the ground truth box each prediction is assigned to, the IoU between the \n",
    "                predictions and their assigned ground truth, and the category labels for each prediction.\n",
    "        \"\"\"\n",
    "        HIGH_COST_VALUE = 100000000\n",
    "        num_gt = gt_bboxes.size(0)\n",
    "        num_bboxes = decoded_bboxes.size(0)\n",
    "\n",
    "        # assign 0 by default\n",
    "        assigned_gt_inds = decoded_bboxes.new_full((num_bboxes, ), 0, dtype=torch.long)\n",
    "        if num_gt == 0 or num_bboxes == 0:\n",
    "            # No ground truth or boxes, return empty assignment\n",
    "            max_overlaps = decoded_bboxes.new_zeros((num_bboxes, ))\n",
    "            if num_gt == 0:\n",
    "                # No truth, assign everything to background\n",
    "                assigned_gt_inds[:] = 0\n",
    "            if gt_labels is None:\n",
    "                assigned_labels = None\n",
    "            else:\n",
    "                assigned_labels = decoded_bboxes.new_full((num_bboxes, ), -1, dtype=torch.long)\n",
    "            return AssignResult(num_gt, assigned_gt_inds, max_overlaps, category_labels=assigned_labels)\n",
    "\n",
    "        # Get info whether a prior is in gt bounding box and also the center of gt bounding box\n",
    "        valid_mask, is_in_boxes_and_center = self.get_in_gt_and_in_center_info(priors, gt_bboxes)\n",
    "\n",
    "        # Extract valid bounding boxes and scores (i.e., those in ground truth boxes and centers)\n",
    "        valid_decoded_bbox = decoded_bboxes[valid_mask]\n",
    "        valid_pred_scores = pred_scores[valid_mask]\n",
    "        num_valid = valid_decoded_bbox.size(0)\n",
    "\n",
    "        # Compute IoU between valid decoded bounding boxes and gt bounding boxes\n",
    "        pairwise_ious = torchvision.ops.generalized_box_iou(valid_decoded_bbox, gt_bboxes)\n",
    "        # Compute IoU cost\n",
    "        iou_cost = -torch.log(pairwise_ious + eps)\n",
    "\n",
    "        # Convert gt_labels to one-hot format and calculate classification cost\n",
    "        gt_onehot_label = F.one_hot(gt_labels.to(torch.int64), pred_scores.shape[-1]).float().unsqueeze(0).repeat(num_valid, 1, 1)\n",
    "        valid_pred_scores = valid_pred_scores.unsqueeze(1).repeat(1, num_gt, 1)\n",
    "        cls_cost = F.binary_cross_entropy(valid_pred_scores.sqrt_(), gt_onehot_label, reduction='none').sum(-1)\n",
    "\n",
    "        # Calculate total cost matrix by combining classification and IoU costs, \n",
    "        # and assign a high cost (HIGH_COST_VALUE) for bboxes not in both boxes and centers\n",
    "        cost_matrix = cls_cost * self.cls_weight + iou_cost * self.iou_weight + (~is_in_boxes_and_center) * HIGH_COST_VALUE\n",
    "\n",
    "        # Perform matching between ground truth and valid bounding boxes based on the cost matrix\n",
    "        matched_pred_ious, matched_gt_inds = self.dynamic_k_matching(cost_matrix, pairwise_ious, num_gt, valid_mask)\n",
    "\n",
    "        # Convert to AssignResult format: assign matched gt indices, labels and IoU scores\n",
    "        assigned_gt_inds[valid_mask] = matched_gt_inds + 1\n",
    "        assigned_labels = assigned_gt_inds.new_full((num_bboxes, ), -1)\n",
    "        assigned_labels[valid_mask] = gt_labels[matched_gt_inds].long()\n",
    "        max_overlaps = assigned_gt_inds.new_full((num_bboxes, ), -HIGH_COST_VALUE, dtype=torch.float32)\n",
    "        max_overlaps[valid_mask] = matched_pred_ious\n",
    "        return AssignResult(num_gt, assigned_gt_inds, max_overlaps, category_labels=assigned_labels)\n",
    "\n",
    "#     def get_in_gt_and_in_center_info(self, priors, gt_bboxes):\n",
    "#         \"\"\"Get the information about whether priors are in ground truth boxes or center.\n",
    "\n",
    "#         Args:\n",
    "#             priors (Tensor): All priors of one image, a 2D-Tensor with shape [num_priors, 4]\n",
    "#                 in [cx, xy, stride_w, stride_y] format.\n",
    "#             gt_bboxes (Tensor): Ground truth bboxes of one image, a 2D-Tensor\n",
    "#                 with shape [num_gts, 4] in [tl_x, tl_y, br_x, br_y] format.\n",
    "\n",
    "#         Returns:\n",
    "#             Tuple[Tensor, Tensor]: The first tensor indicates if the prior is in any ground truth box or center, \n",
    "#             the second tensor specifies if the prior is in both the ground truth box and center.\n",
    "#         \"\"\"\n",
    "\n",
    "#         # Repeat the prior values across the new dimension to facilitate the calculations\n",
    "#         repeated_x = priors[:, 0, None]\n",
    "#         repeated_y = priors[:, 1, None]\n",
    "#         repeated_stride_x = priors[:, 2, None]\n",
    "#         repeated_stride_y = priors[:, 3, None]\n",
    "\n",
    "#         # Calculate deltas (distances from priors to the boundaries of the ground truth boxes)\n",
    "#         deltas = torch.stack([\n",
    "#             repeated_x - gt_bboxes[:, 0], \n",
    "#             repeated_y - gt_bboxes[:, 1], \n",
    "#             gt_bboxes[:, 2] - repeated_x, \n",
    "#             gt_bboxes[:, 3] - repeated_y], dim=1)\n",
    "\n",
    "#         # Check if any value of deltas is positive, which means the prior is within the ground truth box\n",
    "#         is_in_gts = deltas.min(dim=1).values > 0\n",
    "#         # Check if a prior is in any ground truth box\n",
    "#         is_in_gts_all = is_in_gts.any(dim=1)\n",
    "\n",
    "#         # Calculate the centers of the ground truth boxes\n",
    "#         gt_cxs = (gt_bboxes[:, 0] + gt_bboxes[:, 2]) / 2.0\n",
    "#         gt_cys = (gt_bboxes[:, 1] + gt_bboxes[:, 3]) / 2.0\n",
    "\n",
    "#         # Calculate deltas for center boxes (distances from priors to the boundaries of the center boxes)\n",
    "#         ct_deltas = torch.stack([\n",
    "#             repeated_x - (gt_cxs - self.center_radius * repeated_stride_x),\n",
    "#             repeated_y - (gt_cys - self.center_radius * repeated_stride_y),\n",
    "#             (gt_cxs + self.center_radius * repeated_stride_x) - repeated_x,\n",
    "#             (gt_cys + self.center_radius * repeated_stride_y) - repeated_y], dim=1)\n",
    "\n",
    "#         # Check if any value of ct_deltas is positive, which means the prior is within the center box\n",
    "#         is_in_cts = ct_deltas.min(dim=1).values > 0\n",
    "#         # Check if a prior is in any center box\n",
    "#         is_in_cts_all = is_in_cts.any(dim=1)\n",
    "\n",
    "#         # Check if a prior is in either any ground truth box or any center box\n",
    "#         is_in_gts_or_centers = is_in_gts_all | is_in_cts_all\n",
    "#         # Check if a prior is in both any ground truth box and any center box\n",
    "#         is_in_boxes_and_centers = (is_in_gts[is_in_gts_or_centers, :] & is_in_cts[is_in_gts_or_centers, :])\n",
    "\n",
    "#         return is_in_gts_or_centers, is_in_boxes_and_centers\n",
    "\n",
    "    def get_in_gt_and_in_center_info(self, priors, gt_bboxes):\n",
    "        \"\"\"Get the information about whether priors are in ground truth boxes or center.\n",
    "\n",
    "        Args:\n",
    "            priors (Tensor): All priors of one image, a 2D-Tensor with shape [num_priors, 4]\n",
    "                in [cx, xy, stride_w, stride_y] format.\n",
    "            gt_bboxes (Tensor): Ground truth bboxes of one image, a 2D-Tensor\n",
    "                with shape [num_gts, 4] in [tl_x, tl_y, br_x, br_y] format.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Tensor, Tensor]: The first tensor indicates if the prior is in any ground truth box or center, \n",
    "            the second tensor specifies if the prior is in both the ground truth box and center.\n",
    "        \"\"\"\n",
    "\n",
    "        # Calculate the centers of the ground truth boxes\n",
    "        gt_cxs = (gt_bboxes[:, 0] + gt_bboxes[:, 2]) / 2.0\n",
    "        gt_cys = (gt_bboxes[:, 1] + gt_bboxes[:, 3]) / 2.0\n",
    "\n",
    "        # Prepare the boundaries for the ground truth boxes\n",
    "        gt_bounds = torch.stack([\n",
    "            priors[:, :2, None] - gt_bboxes[:, :2], \n",
    "            gt_bboxes[:, 2:] - priors[:, :2, None]\n",
    "        ], dim=-1)\n",
    "\n",
    "        print(\"Shape of gt_bounds: \", gt_bounds.shape)\n",
    "\n",
    "        # Check if priors are inside the ground truth boxes\n",
    "        is_in_gts = gt_bounds.min(dim=-1).values > 0\n",
    "        print(\"Shape of is_in_gts: \", is_in_gts.shape)\n",
    "        is_in_gts_all = is_in_gts.any(dim=1)\n",
    "\n",
    "        # Prepare the boundaries for the center boxes\n",
    "        ct_bounds = torch.stack([\n",
    "            priors[:, :2, None] - (gt_cxs[None, :] - self.center_radius * priors[:, 2:, None]), \n",
    "            (gt_cxs[None, :] + self.center_radius * priors[:, 2:, None]) - priors[:, :2, None]\n",
    "        ], dim=-1)\n",
    "\n",
    "        print(\"Shape of ct_bounds: \", ct_bounds.shape)\n",
    "\n",
    "        # Check if priors are inside the center boxes\n",
    "        is_in_cts = ct_bounds.min(dim=-1).values > 0\n",
    "        print(\"Shape of is_in_cts: \", is_in_cts.shape)\n",
    "        is_in_cts_all = is_in_cts.any(dim=1)\n",
    "\n",
    "        # Check if priors are in either any ground truth box or any center box\n",
    "        is_in_gts_or_centers = is_in_gts_all | is_in_cts_all\n",
    "\n",
    "        # Check if priors are in both ground truth boxes and centers\n",
    "        is_in_boxes_and_centers = is_in_gts_all & is_in_cts_all\n",
    "        \n",
    "        print(\"Shape of is_in_boxes_and_centers: \", is_in_boxes_and_centers.shape)\n",
    "\n",
    "        return is_in_gts_or_centers, is_in_boxes_and_centers\n",
    "\n",
    "    \n",
    "    def dynamic_k_matching(self, cost, pairwise_ious, num_gt, valid_mask):\n",
    "        \"\"\"\n",
    "        This method performs dynamic k-matching. This is a core part of the SimOTA assignment\n",
    "        where each ground truth object dynamically chooses k bounding box predictions that best \n",
    "        match itself according to the cost matrix. Then, if there are any conflicts (i.e., one \n",
    "        prediction is selected by multiple ground truths), the conflicts are resolved by choosing \n",
    "        the pair with the smallest cost.\n",
    "\n",
    "        Args:\n",
    "            cost (Tensor): A 2D tensor representing the cost matrix calculated from both \n",
    "                classification cost and regression IoU cost. Shape is [num_priors, num_gts].\n",
    "            pairwise_ious (Tensor): A 2D tensor representing IoU scores between predictions and \n",
    "                ground truths. Shape is [num_priors, num_gts].\n",
    "            num_gt (int): The number of ground truth boxes.\n",
    "            valid_mask (Tensor): A 1D tensor representing which predicted boxes are valid based \n",
    "                on being in gt bboxes and in centers. Shape is [num_priors].\n",
    "\n",
    "        Returns:\n",
    "            matched_pred_ious (Tensor): IoU scores for matched pairs. Shape is [num_priors].\n",
    "            matched_gt_inds (Tensor): The indices of the ground truth for each prior. Shape is [num_priors].\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize the matching matrix with zeros\n",
    "        matching_matrix = torch.zeros_like(cost)\n",
    "\n",
    "        # Select the top k IoUs for dynamic-k calculation\n",
    "        topk_ious, _ = torch.topk(pairwise_ious, self.candidate_topk, dim=0)\n",
    "\n",
    "        # Calculate dynamic k for each ground truth\n",
    "        dynamic_ks = topk_ious.sum(0).int().clamp(min=1)\n",
    "\n",
    "        # For each ground truth, find top k matching priors based on smallest cost\n",
    "        _, pos_idx = cost.topk(k=dynamic_ks.max().item(), dim=0, largest=False)\n",
    "        for gt_idx in range(num_gt):\n",
    "            matching_matrix[pos_idx[:dynamic_ks[gt_idx], gt_idx], gt_idx] = 1\n",
    "\n",
    "        # If a prior matches multiple ground truths, keep only the one with smallest cost\n",
    "        prior_match_gt_mask = matching_matrix.sum(1) > 1\n",
    "        if prior_match_gt_mask.any():\n",
    "            _, cost_argmin = cost[prior_match_gt_mask].min(dim=1)\n",
    "            matching_matrix[prior_match_gt_mask].zero_()\n",
    "            matching_matrix[prior_match_gt_mask, cost_argmin] = 1\n",
    "\n",
    "        # Update the valid mask based on final matches\n",
    "        valid_mask[valid_mask.clone()] = matching_matrix.sum(1) > 0\n",
    "\n",
    "        # Get the final matched ground truth indices and IoUs for valid predicted boxes\n",
    "        fg_mask_inboxes = matching_matrix.sum(1) > 0\n",
    "        matched_gt_inds = matching_matrix[fg_mask_inboxes].argmax(1)\n",
    "        matched_pred_ious = (matching_matrix * pairwise_ious).sum(1)[fg_mask_inboxes]\n",
    "\n",
    "        return matched_pred_ious, matched_gt_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
